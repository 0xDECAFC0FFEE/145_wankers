{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of probabilistic matrix factorisation\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import csv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_names = Path(\"dataset\")/\"genome-tags.csv\"                   # tag name lookup\n",
    "movie_review_relevance = Path(\"dataset\")/\"genome-scores.csv\"    # movieid/tagid/relevance\n",
    "movie_genres = Path(\"dataset\")/\"movies.csv\"                     # movieid/movie title/genres\n",
    "reviews = Path(\"dataset\")/\"tags_shuffled_rehashed.csv\"          # userid/movieid/tag\n",
    "train_set = Path(\"dataset\")/\"train_ratings_binary.csv\"          # train set - userid/movieid/ratings\n",
    "val_set = Path(\"dataset\")/\"val_ratings_binary.csv\"              # val set - userid/movieid/ratings\n",
    "test_set = Path(\"dataset\")/\"test_ratings.csv\"                   # test set - userid/movieids\n",
    "\n",
    "NUM_MOVIES = 26744\n",
    "NUM_USERS = 138493\n",
    "NUM_TRAINING_SET = 11946576\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating lookuptable with mids from dataset/train_ratings_binary.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1700d3582e1482b8081c36bc9aafb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5dd35b27131a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mnext_unassigned_mid\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0madd_movieids_to_lookuptable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0madd_movieids_to_lookuptable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0madd_movieids_to_lookuptable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5dd35b27131a>\u001b[0m in \u001b[0;36madd_movieids_to_lookuptable\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mmovieid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmovieid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovieid_mid_lookup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/csv.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mlf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# internal movieids are used as movieids aren't contiguous\n",
    "userid_uid_lookup = lambda userid: userid-1\n",
    "\n",
    "movieid_mid_lookup = {}\n",
    "next_unassigned_mid = 0\n",
    "\n",
    "def add_movieids_to_lookuptable(filename):\n",
    "    global next_unassigned_mid\n",
    "\n",
    "    print(f\"updating lookuptable with mids from {filename}\")\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for rating in tqdm(reader):\n",
    "            movieid = int(float(rating[\"movieId\"]))\n",
    "            if movieid not in movieid_mid_lookup:\n",
    "                movieid_mid_lookup[movieid] = next_unassigned_mid\n",
    "                next_unassigned_mid += 1\n",
    "\n",
    "add_movieids_to_lookuptable(train_set)\n",
    "add_movieids_to_lookuptable(val_set)\n",
    "add_movieids_to_lookuptable(test_set)\n",
    "add_movieids_to_lookuptable(movie_genres)\n",
    "\n",
    "with open(\"movieid_mid_lookup\", \"wb+\") as lookup_file:\n",
    "    pickle.dump(movieid_mid_lookup, lookup_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_uid_lookup = lambda userid: userid-1\n",
    "\n",
    "with open(\"movieid_mid_lookup\", \"rb\") as lookup_file:\n",
    "    movieid_mid_lookup = pickle.load(lookup_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving dataset from dataset/train_ratings_binary.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91f6d6407b040b49cacd0e2baff81c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "retrieving dataset from dataset/val_ratings_binary.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea6d7332bd04da490632f4324b5699f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "movie_summary_matrix = load_npz(\"movie_summary_matrix.npz\")\n",
    "\n",
    "def get_dataset(filename, include_ys=True):\n",
    "    print(f\"retrieving dataset from {filename}\")\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        user_Xs = []\n",
    "        movie_Xs = []\n",
    "        ys = []\n",
    "        for rating in tqdm(reader):\n",
    "            userid = int(float(rating[\"userId\"]))\n",
    "            uid = userid_uid_lookup(userid)\n",
    "            user_Xs.append(uid)\n",
    "            \n",
    "            movieid = int(float(rating[\"movieId\"]))\n",
    "            mid = movieid_mid_lookup[movieid]\n",
    "            movie_Xs.append(mid)\n",
    "            \n",
    "            if include_ys:\n",
    "                score = 1 if (rating[\"rating\"] == \"1\") else -1\n",
    "                ys.append(score)\n",
    "    if include_ys:\n",
    "        return np.array(user_Xs), np.array(movie_Xs), np.array(ys)\n",
    "    else:\n",
    "        return np.array(user_Xs), np.array(movie_Xs)\n",
    "\n",
    "def batchify(*args, batch_size=1000, shuffle=True):\n",
    "    if batch_size == -1:\n",
    "        return args\n",
    "    \n",
    "    num_elems = len(args[0])\n",
    "    \n",
    "    if shuffle:\n",
    "        shuffle_indices = np.arange(num_elems, dtype=np.int64)\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for i in range(0, num_elems, batch_size):\n",
    "            array_indices = shuffle_indices[i: i+batch_size]\n",
    "            try:\n",
    "                yield [arg[array_indices] for arg in args]\n",
    "            except:\n",
    "                raise Exception(\"args to batchify must be numpy arrays if shuffle True\")\n",
    "    else:\n",
    "        for i in range(0, num_elems, batch_size):\n",
    "            yield [arg[i: i+batch_size] for arg in args]\n",
    "\n",
    "def genre_parser(genre):\n",
    "    if genre == \"(no genres listed)\":\n",
    "        return [\"none/other\"]\n",
    "    return genre.split(\"|\")\n",
    "\n",
    "ALL_GENRES = ['Drama', 'Comedy', 'Thriller', 'Romance', 'Action', 'Crime', 'Horror', 'Documentary', 'Adventure', 'Sci-Fi', 'Mystery', 'Fantasy', 'War', 'Children', 'Musical', 'Animation', 'Western', 'Film-Noir', 'none/other', 'IMAX']\n",
    "with open(movie_genres, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    movie_genres_one_hot = {movieid_mid_lookup[int(float(movie[\"movieId\"]))]: np.array([genre in movie[\"genres\"] for genre in ALL_GENRES]) for movie in reader}        \n",
    "\n",
    "user_Xs, movie_Xs, ys = get_dataset(train_set)\n",
    "# user_val_Xs, movie_val_Xs = get_dataset(test_set, include_ys=False)\n",
    "user_val_Xs, movie_val_Xs, val_ys = get_dataset(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drama', 'Comedy', 'Thriller', 'Romance', 'Action', 'Crime', 'Horror', 'Documentary', 'Adventure', 'Sci-Fi', 'Mystery', 'Fantasy', 'War', 'Children', 'Musical', 'Animation', 'Western', 'Film-Noir', 'none/other', 'IMAX']\n",
      "Adventure|Animation|Children|Comedy|Fantasy\n",
      "[False  True False False False False False False  True False False  True\n",
      " False  True False  True False False False False]\n",
      "Adventure|Children|Fantasy\n",
      "[False False False False False False False False  True False False  True\n",
      " False  True False False False False False False]\n",
      "Comedy|Romance\n",
      "[False  True False  True False False False False False False False False\n",
      " False False False False False False False False]\n",
      "Comedy|Drama|Romance\n",
      "[ True  True False  True False False False False False False False False\n",
      " False False False False False False False False]\n",
      "Comedy\n",
      "[False  True False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(ALL_GENRES)\n",
    "with open(movie_genres, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for i, movie in enumerate(reader):\n",
    "        print(movie[\"genres\"])\n",
    "        print(movie_genres_one_hot[movieid_mid_lookup[int(float(movie[\"movieId\"]))]])\n",
    "        if i  > 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_genre_count = 0\n",
    "# total = 0\n",
    "\n",
    "# with open(test_set, newline=\"\") as csvfile:\n",
    "#     reader = csv.DictReader(csvfile)\n",
    "#     for rating in tqdm(reader):\n",
    "#         if movieid_mid_lookup[int(float(rating[\"movieId\"]))] not in movie_genres_one_hot:\n",
    "#             no_genre_count += 1\n",
    "#         total += 1\n",
    "\n",
    "# print(f\"{no_genre_count}/{total} entries in the test data doesn't have genre info ({no_genre_count/total}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no memory - implicitly calculating user movie matrix from now on\n",
    "\n",
    "# movie_embeddings = tf.Variable(tf.random_normal([5, NUM_MOVIES], stddev=0.03, dtype=tf.float32))\n",
    "# user_embeddings = tf.Variable(tf.random_normal([NUM_USERS, 5], stddev=0.03, dtype=tf.float32))\n",
    "# movie_bias = tf.Variable(tf.random_normal([1, NUM_MOVIES], stddev=0.03, dtype=tf.float32))\n",
    "# user_bias = tf.Variable(tf.random_normal([NUM_USERS, 1], stddev=0.03, dtype=tf.float32))\n",
    "\n",
    "# user_movie_score = tf.tensordot(user_embeddings, movie_embeddings, axes = 1)+.14*tf.tile(movie_bias, [NUM_USERS, 1]) +.87*tf.tile(user_bias, [1, NUM_MOVIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_embedding_rows shape (?, 20)\n",
      "user_slice_bias shape (?,)\n",
      "(?,)\n",
      "(?, 40)\n",
      "(?, 20)\n",
      "(?, 40)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 40\n",
    "assert embedding_dim > 20\n",
    "\n",
    "movie_genre_embeddings = tf.placeholder(dtype=tf.float32, shape=[None, 20])\n",
    "movie_embeddings = tf.Variable(tf.random_normal([NUM_MOVIES, embedding_dim-20], stddev=0.03, dtype=tf.float32))\n",
    "user_embeddings = tf.Variable(tf.random_normal([NUM_USERS, embedding_dim], stddev=0.03, dtype=tf.float32))\n",
    "movie_bias = tf.Variable(tf.random_normal([NUM_MOVIES], stddev=0.03, dtype=tf.float32))\n",
    "user_bias = tf.Variable(tf.random_normal([NUM_USERS], stddev=0.03, dtype=tf.float32))\n",
    "\n",
    "# user_movie_score = tf.tensordot(user_embeddings, movie_embeddings, axes = 1)+.14*tf.tile(movie_bias, [NUM_USERS, 1]) +.87*tf.tile(user_bias, [1, NUM_MOVIES])\n",
    "\n",
    "user_slice_idxs = tf.placeholder(dtype=tf.int64, shape=[None, 1])\n",
    "movie_slice_idxs = tf.placeholder(dtype=tf.int64, shape=[None, 1])\n",
    "# user_bias_idxs = tf.placeholder(dtype=tf.int64, shape=[None, 1])\n",
    "# movie_bias_idxs = tf.placeholder(dtype=tf.int64, shape=[None, 1])\n",
    "\n",
    "user_embedding_columns = tf.reshape(tf.gather_nd(user_embeddings, user_slice_idxs), [-1, embedding_dim])\n",
    "movie_embedding_rows = tf.reshape(tf.gather_nd(movie_embeddings, movie_slice_idxs), [-1, embedding_dim-20])\n",
    "print(\"movie_embedding_rows shape\", movie_embedding_rows.shape)\n",
    "\n",
    "user_slice_bias = tf.gather_nd(user_bias, user_slice_idxs)\n",
    "movie_slice_bias = tf.gather_nd(movie_bias, movie_slice_idxs)\n",
    "print(\"user_slice_bias shape\", user_slice_bias.shape)\n",
    "\n",
    "pred_y = tf.reduce_sum(user_embedding_columns * tf.concat((movie_embedding_rows, movie_genre_embeddings), axis=1), axis=1) + .14*movie_slice_bias + .87*user_slice_bias\n",
    "print(pred_y.shape)\n",
    "print(tf.concat((movie_embedding_rows, movie_genre_embeddings), axis=1).shape)\n",
    "print(movie_embedding_rows.shape)\n",
    "print(user_embedding_columns.shape)\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-502b1275ec71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_slices(user_Xs, movie_Xs, embedding_dim):\n",
    "    user_slice_idxs = [[user_X] for user_X in user_Xs]\n",
    "    movie_slice_idxs = [[movie_X] for movie_X in movie_Xs]\n",
    "\n",
    "    return [np.array(user_slice_idxs).reshape([-1, 1]), np.array(movie_slice_idxs).reshape([-1, 1])]\n",
    "\n",
    "learning_rate = .05\n",
    "epochs = 15\n",
    "\n",
    "loss = tf.reduce_mean(tf.squared_difference(pred_y, y_true))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), leave=False):\n",
    "        for b_m_Xs, b_u_Xs, b_ys in batchify(movie_Xs, user_Xs, ys, batch_size=1000000):\n",
    "#             print(\"batch vals\", b_m_Xs, b_u_Xs, b_ys)\n",
    "            \n",
    "            slice_indices = compute_slices(b_u_Xs, b_m_Xs, embedding_dim)\n",
    "            user_slice, movie_slice = slice_indices\n",
    "            \n",
    "#             print(\"user_slice indexes shape\", np.array(user_slice).shape)\n",
    "#             print(\"movie bias indexes shape\", np.array(m_bias_slice).shape)\n",
    "            \n",
    "            genres = np.array([movie_genres_one_hot[x] for x in b_m_Xs])\n",
    "            feed_dict = {user_slice_idxs: user_slice, \n",
    "                         movie_slice_idxs: movie_slice, \n",
    "                         movie_genre_embeddings: genres,\n",
    "                         y_true: b_ys}\n",
    "            _, lossval, pred_y_vals = sess.run((train_step, loss, pred_y), feed_dict=feed_dict)\n",
    "            print(\"train loss\", lossval, \"pred ys\", pred_y_vals[:10].flatten(), \"y_true\", b_ys[:10].flatten())\n",
    "\n",
    "        print(\"computing val acc...\")\n",
    "        val_slice_indices = compute_slices(user_val_Xs, movie_val_Xs, embedding_dim)\n",
    "        user_val_slice, movie_val_slice = val_slice_indices\n",
    "        genres = np.array([movie_genres_one_hot[x] for x in movie_val_Xs])\n",
    "        feed_dict = {user_slice_idxs: user_val_slice, \n",
    "                         movie_slice_idxs: movie_val_slice,\n",
    "                         movie_genre_embeddings: genres,\n",
    "                         y_true: val_ys}\n",
    "        val_y_pred, val_loss_val = sess.run((pred_y, loss), feed_dict=feed_dict)\n",
    "        print(\"val loss\", val_loss_val)\n",
    "        print(\"val acc\", sum([((1 if pred > .5 else -1) == true) for pred, true in zip(val_y_pred, val_ys)])/len(val_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "27278",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9dced7b4d78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_genres_one_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m27278\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 27278"
     ]
    }
   ],
   "source": [
    "print(movie_genres_one_hot[27278])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999236, 1) (3999236, 1) (3999236,)\n",
      "(11946576, 1) (11946576, 1) (11946576,)\n"
     ]
    }
   ],
   "source": [
    "val_slice_indices = compute_slices(user_val_Xs, movie_val_Xs, embedding_dim)\n",
    "user_val_slice, movie_val_slice = val_slice_indices\n",
    "\n",
    "print(user_val_slice.shape, movie_val_slice.shape, np.array(val_ys).shape)\n",
    "\n",
    "slice_indices = compute_slices(user_Xs, movie_Xs, embedding_dim)\n",
    "user_slice, movie_slice = slice_indices\n",
    "\n",
    "print(user_slice.shape, movie_slice.shape, np.array(ys).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11946576 11946576\n",
      "3999236 3999236\n"
     ]
    }
   ],
   "source": [
    "print(len(user_Xs), len(ys))\n",
    "print(len(user_val_Xs), len(val_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
