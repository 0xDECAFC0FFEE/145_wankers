{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# implementation of probabilistic matrix factorisation\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=10)\n",
    "np.core.arrayprint._line_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieid_mid_lookup = get_movieid_mid_lookup(recompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28988it [00:00, 289874.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading movie tags from csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11709768it [00:40, 289243.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381\n"
     ]
    }
   ],
   "source": [
    "# tags = set()\n",
    "# max_tag, min_tag = 0, math.inf\n",
    "\n",
    "# with open(movie_review_relevance, newline=\"\") as csvfile:\n",
    "#     reader = csv.DictReader(csvfile)\n",
    "#     for rating in tqdm(reader):\n",
    "# #         movieid = int(float(rating[\"movieId\"]))\n",
    "#         tagid = int(float(rating[\"tagId\"]))\n",
    "# #         relevance = float(rating[\"relevance\"])\n",
    "#         tags.add(tagid)\n",
    "#         max_tag = max(max_tag, tagid)\n",
    "#         min_tag = min(min_tag, tagid)\n",
    "\n",
    "movie_tag_mids, movie_tag_relevances = get_movie_tag_relevances()\n",
    "print(len(movie_tag_mids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "(?, 1128) (?, 1128)\n"
     ]
    }
   ],
   "source": [
    "# the model\n",
    "\n",
    "embedding_dim = 40\n",
    "assert embedding_dim > 20\n",
    "\n",
    "movie_tag_relevances_var = tf.placeholder(dtype=tf.float64, shape=[None, NUM_TAGS])\n",
    "\n",
    "W1 = tf.Variable(tf.contrib.layers.xavier_initializer()(shape=[NUM_TAGS, 5000], dtype=tf.float64))\n",
    "b1 = tf.Variable(initial_value=np.zeros(shape=[5000], dtype=np.float64))\n",
    "l1 = tf.nn.relu(tf.matmul(movie_tag_relevances_var, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.contrib.layers.xavier_initializer()(shape=[5000, NUM_TAGS], dtype=tf.float64))\n",
    "b2 = tf.Variable(initial_value=np.zeros(shape=[NUM_TAGS], dtype=np.float64))\n",
    "pred_y = tf.nn.sigmoid(tf.matmul(l1, W2) + b2)\n",
    "\n",
    "print(movie_tag_relevances_var.shape, pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples 9381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "train loss 0.17274883105558303\n",
      "val loss 0.048175727233211244\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.98001133e-09 2.42567593e-09 1.92189762e-09 1.99368831e-09\n",
      " 4.70511978e-09 3.33418693e-09 6.21247592e-09 5.52579411e-09\n",
      " 8.81433618e-10 4.40224616e-10 ... 1.19704135e-09 8.07589676e-10\n",
      " 1.21636765e-09 3.10744553e-09 1.02427044e-08 1.57594173e-09\n",
      " 1.24971828e-09 4.47926206e-09 5.11551599e-09 2.26704748e-09]\n",
      "\n",
      "training\n",
      "train loss 0.0356349633305217\n",
      "val loss 0.048280440413099965\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.03416495e-24 2.95127287e-24 2.36816081e-24 3.28005063e-24\n",
      " 1.76292626e-23 7.34721158e-24 1.75761712e-23 2.21748894e-23\n",
      " 9.44985123e-25 2.52978265e-25 ... 1.50044527e-24 6.21969299e-25\n",
      " 1.09438313e-24 4.91184160e-24 1.29690496e-22 1.99591737e-24\n",
      " 1.05381308e-24 9.32331441e-24 1.75478637e-23 2.64432989e-24]\n",
      "\n",
      "training\n",
      "train loss 0.03597500167024199\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [5.00635484e-41 8.51584953e-41 7.26967766e-41 1.47715186e-40\n",
      " 1.68879700e-39 3.89250176e-40 1.06995031e-39 2.17064879e-39\n",
      " 3.05292203e-41 4.61215279e-42 ... 5.43894694e-41 1.33646092e-41\n",
      " 2.67730237e-41 1.79603638e-40 4.36298102e-38 6.91677422e-41\n",
      " 2.30409138e-41 4.22677862e-40 1.41188414e-39 6.92068418e-41]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434455\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [6.76868451e-58 1.33713750e-57 1.24312597e-57 3.82858484e-57\n",
      " 8.82836136e-56 1.10801748e-56 3.30558176e-56 1.12358183e-55\n",
      " 6.07463536e-58 5.37874168e-59 ... 1.17829991e-57 1.71527183e-58\n",
      " 3.82003252e-58 3.48977679e-57 7.74799407e-54 1.38679724e-57\n",
      " 2.88494007e-58 9.86067587e-57 5.96323481e-56 9.60189667e-58]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.91036965e-74 4.33673078e-74 4.44448006e-74 2.08447696e-73\n",
      " 9.23414385e-72 6.34339268e-73 1.98807494e-72 1.14525700e-71\n",
      " 2.66130850e-74 1.43472990e-75 ... 5.51496542e-74 4.82351857e-75\n",
      " 1.17373632e-74 1.37432957e-73 2.61286143e-69 5.91246814e-74\n",
      " 7.74080846e-75 4.55888579e-73 4.96185351e-72 2.71683995e-74]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.15633054e-90 5.56617820e-90 6.32556291e-90 4.48511421e-89\n",
      " 3.64123308e-87 1.39544026e-88 4.49957761e-88 4.36876739e-87\n",
      " 4.77013986e-90 1.62261607e-91 ... 1.04149222e-89 5.59450819e-91\n",
      " 1.46718337e-90 2.10749618e-89 3.12757088e-84 1.00965027e-89\n",
      " 8.45713527e-91 8.06661999e-89 1.55105512e-87 3.03107029e-90]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.35489015e-105 3.94106739e-105 4.96953627e-105 5.25901722e-104\n",
      " 7.48569974e-102 1.63965081e-103 5.36602924e-103 8.64600544e-102\n",
      " 4.77855903e-105 1.06105351e-106 ... 1.08970033e-104 3.68102720e-106\n",
      " 1.03080216e-105 1.75728008e-104 1.82969850e-098 9.51909649e-105\n",
      " 5.20882755e-106 7.64424652e-104 2.53379410e-102 1.86638822e-105]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [5.55900123e-120 1.80649337e-119 2.52379654e-119 3.91877528e-118\n",
      " 9.38511104e-116 1.20791331e-117 3.97402046e-117 1.04076993e-115\n",
      " 3.10500071e-119 4.64440502e-121 ... 7.34431157e-119 1.60059374e-120\n",
      " 4.74877938e-120 9.36396132e-119 6.11628786e-112 5.78036381e-119\n",
      " 2.11398329e-120 4.56927007e-118 2.53974806e-116 7.46334971e-120]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.58330028e-133 5.70172897e-133 8.80039961e-133 1.96648621e-131\n",
      " 7.62506253e-129 5.93890203e-131 1.95097702e-130 8.10995987e-129\n",
      " 1.38198459e-132 1.43373092e-134 ... 3.37124132e-132 4.86674654e-134\n",
      " 1.51955422e-133 3.39547407e-132 1.24276619e-124 2.39567768e-132\n",
      " 5.99452136e-134 1.83762187e-131 1.66373515e-129 2.06469997e-133]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [3.13465367e-146 1.24139375e-145 2.10889723e-145 6.64474480e-144\n",
      " 4.02426291e-141 1.95444730e-143 6.38079877e-143 4.10525638e-141\n",
      " 4.20105357e-145 3.10647108e-147 ... 1.05213273e-144 1.03268363e-146\n",
      " 3.37427415e-146 8.40158748e-145 1.54189540e-136 6.77301930e-145\n",
      " 1.18710919e-146 4.99324778e-144 7.15076832e-142 3.96293710e-146]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [4.16112751e-158 1.79939579e-157 3.34979238e-157 1.45814802e-155\n",
      " 1.33335353e-152 4.15921879e-155 1.34525300e-154 1.30540306e-152\n",
      " 8.39365712e-157 4.53626456e-159 ... 2.14992664e-156 1.47191698e-158\n",
      " 5.00889827e-158 1.37004088e-156 1.13214712e-147 1.25875299e-156\n",
      " 1.58129653e-158 8.86469558e-156 1.95020021e-153 5.09668078e-158]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [3.48910506e-169 1.63775617e-168 3.32502146e-168 1.95954412e-166\n",
      " 2.61979816e-163 5.40507741e-166 1.72822482e-165 2.46453349e-163\n",
      " 1.03740176e-167 4.19599715e-170 ... 2.70829735e-167 1.32599834e-169\n",
      " 4.67889530e-169 1.38968295e-167 4.65985203e-158 1.44878864e-167\n",
      " 1.33433754e-169 9.71430683e-167 3.19027091e-164 4.14131350e-169]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.71801230e-179 8.69652090e-179 1.91631790e-178 1.49878117e-176\n",
      " 2.84587197e-173 3.99385873e-176 1.26047153e-175 2.57632170e-173\n",
      " 7.36318109e-178 2.27901419e-180 ... 1.95417179e-177 7.00492191e-180\n",
      " 2.55350083e-179 8.15517539e-178 1.00508337e-167 9.59813145e-178\n",
      " 6.62100833e-180 6.11565400e-177 2.91750868e-174 1.97658471e-179]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [4.57367424e-189 2.48179135e-188 5.90725227e-188 6.01411392e-186\n",
      " 1.57850793e-182 1.54781494e-185 4.81751177e-185 1.37770891e-182\n",
      " 2.76343749e-187 6.68100219e-190 ... 7.43845734e-187 1.99659930e-189\n",
      " 7.49468782e-189 2.55198450e-187 1.05250154e-176 3.37172504e-187\n",
      " 1.77776970e-189 2.04028930e-186 1.37741909e-183 5.10455600e-189]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [6.03098829e-198 3.48954530e-197 8.92741335e-197 1.16150167e-194\n",
      " 4.10961255e-191 2.88816306e-194 8.86230603e-194 3.46425872e-191\n",
      " 5.02577680e-196 9.67594360e-199 ... 1.36956825e-195 2.81175030e-198\n",
      " 1.08363351e-197 3.90604538e-196 4.93276234e-185 5.75795614e-196\n",
      " 2.36617928e-198 3.31065482e-195 3.08507818e-192 6.53767991e-198]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [3.60287987e-206 2.21190681e-205 6.05276256e-205 9.88857697e-203\n",
      " 4.60780446e-199 2.37763499e-202 7.19267572e-202 3.75841890e-199\n",
      " 4.05340103e-204 6.32718806e-207 ... 1.11661156e-203 1.78871613e-206\n",
      " 7.05916537e-206 2.67702800e-204 9.52147763e-193 4.37541031e-204\n",
      " 1.42741724e-206 2.39324800e-203 3.00646740e-200 3.79859807e-206]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [8.91893805e-214 5.78273572e-213 1.68481280e-212 3.39935470e-210\n",
      " 2.04119806e-206 7.91269920e-210 2.36025918e-209 1.61419757e-206\n",
      " 1.32707601e-211 1.70762329e-214 ... 3.69068115e-211 4.70010666e-214\n",
      " 1.89520605e-213 7.52003767e-212 6.96499135e-200 1.35426897e-211\n",
      " 3.56859699e-214 7.05811824e-211 1.16900961e-207 9.15859504e-214]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [8.37660282e-221 5.71077614e-220 1.76377884e-219 4.32699864e-217\n",
      " 3.28126254e-213 9.76382799e-217 2.87282632e-216 2.52048732e-213\n",
      " 1.61636231e-218 1.74126701e-221 ... 4.53261433e-218 4.66980082e-221\n",
      " 1.92029176e-220 7.93501484e-219 1.77843745e-206 1.56461561e-218\n",
      " 3.38462699e-221 7.78548514e-218 1.66477086e-214 8.39041812e-221]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.74034546e-227 1.95655691e-226 6.37891738e-226 1.87487159e-223\n",
      " 1.76223951e-219 4.10737200e-223 1.19262822e-222 1.31739655e-219\n",
      " 6.72998115e-225 6.15680239e-228 ... 1.90109299e-224 1.61070746e-227\n",
      " 6.74240776e-227 2.88917521e-225 1.46310644e-212 6.20022322e-225\n",
      " 1.11792947e-227 2.95195382e-224 7.99142549e-221 2.68134055e-227]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.87459097e-233 2.14143583e-232 7.34067624e-232 2.54933942e-229\n",
      " 2.91900556e-225 5.43082232e-229 1.55702033e-228 2.12765993e-225\n",
      " 8.82683606e-231 6.94845241e-234 ... 2.50963090e-230 1.77552072e-233\n",
      " 7.55338545e-233 3.34392769e-231 3.58927463e-218 7.76515512e-231\n",
      " 1.18363815e-233 3.54540929e-230 1.19312542e-226 2.75158057e-233]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [8.93069534e-239 6.91765268e-238 2.48390602e-237 1.00616477e-234\n",
      " 1.38110737e-230 2.08762578e-234 5.91330035e-234 9.83297001e-231\n",
      " 3.37176423e-236 2.31196251e-239 ... 9.64184713e-236 5.77778752e-239\n",
      " 2.49432304e-238 1.13707401e-236 2.43751507e-223 2.84139352e-236\n",
      " 3.71023645e-239 1.24704253e-235 5.12858780e-232 8.37468073e-239]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [7.61784702e-244 6.11597484e-243 2.29220822e-242 1.06999569e-239\n",
      " 1.73481946e-235 2.16576566e-239 6.06475499e-239 1.20847944e-235\n",
      " 3.48102850e-241 2.10266800e-244 ... 1.00053425e-240 5.14597312e-244\n",
      " 2.25140350e-243 1.05374579e-241 4.26866654e-228 2.81858260e-241\n",
      " 3.19185320e-244 1.19190384e-240 5.89598164e-237 7.00796208e-244]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.66013716e-248 1.37741809e-247 5.37051001e-247 2.85677090e-244\n",
      " 5.39605790e-240 5.64968630e-244 1.56509319e-243 3.68400640e-240\n",
      " 9.04691645e-246 4.86447469e-249 ... 2.61216090e-245 1.16742036e-248\n",
      " 5.16968234e-248 2.47781643e-246 1.80192493e-232 7.05908060e-246\n",
      " 7.01199483e-249 2.88291877e-245 1.69022356e-241 1.50019402e-248]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [8.63441604e-253 7.38378684e-252 2.98552901e-251 1.79103872e-248\n",
      " 3.89129329e-244 3.46601362e-248 9.50498709e-248 2.60795850e-244\n",
      " 5.53446120e-250 2.67463683e-253 ... 1.60446576e-249 6.30282439e-253\n",
      " 2.82168492e-252 1.38181704e-250 1.72015219e-236 4.17311649e-250\n",
      " 3.67460024e-253 1.64973563e-249 1.13071060e-245 7.67431148e-253]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.00524733e-256 8.83796063e-256 3.69519116e-255 2.47583506e-252\n",
      " 6.11566494e-248 4.69542522e-252 1.27550290e-251 4.02927804e-248\n",
      " 7.48199417e-254 3.27878816e-257 ... 2.17691416e-253 7.59626922e-257\n",
      " 3.43465751e-256 1.71496176e-254 3.49711343e-240 5.46588358e-254\n",
      " 4.30858106e-257 2.09627289e-253 1.65841687e-249 8.79848906e-257]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.46633398e-260 2.22411865e-259 9.59008002e-259 7.11204559e-256\n",
      " 1.97601509e-251 1.32373129e-255 3.56422408e-255 1.28152276e-251\n",
      " 2.10621178e-257 8.43831106e-261 ... 6.14794191e-257 1.92431585e-260\n",
      " 8.77973869e-260 4.46137193e-258 1.43084994e-243 1.49436328e-257\n",
      " 1.06415192e-260 5.57190143e-257 5.02864777e-253 2.12820426e-260]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.20501199e-263 1.11223790e-262 4.93356157e-262 4.01603857e-259\n",
      " 1.24272680e-254 7.34597699e-259 1.96172378e-258 7.94332914e-255\n",
      " 1.16766978e-260 4.30925265e-264 ... 3.41826295e-260 9.68391394e-264\n",
      " 4.45477823e-263 2.29984813e-261 1.11731555e-246 8.06440884e-261\n",
      " 5.23171022e-264 2.92929853e-260 2.98326088e-256 1.02623771e-263]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.11195865e-266 1.04843672e-265 4.77310599e-265 4.23208620e-262\n",
      " 1.44531972e-257 7.61755458e-262 2.01874222e-261 9.11556887e-258\n",
      " 1.21009351e-263 4.14228693e-267 ... 3.55166936e-263 9.18305062e-267\n",
      " 4.25610037e-266 2.22902793e-264 1.58447300e-249 8.15253138e-264\n",
      " 4.85576258e-267 2.89045801e-263 3.28861147e-259 9.35579797e-267]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.84443522e-269 1.77328927e-268 8.26810199e-268 7.92834944e-265\n",
      " 2.96339730e-260 1.40599662e-264 3.69971839e-264 1.84616297e-260\n",
      " 2.23279788e-266 7.13476648e-270 ... 6.56864924e-266 1.56195521e-269\n",
      " 7.28873061e-269 3.86719550e-267 3.89561347e-252 1.47029449e-266\n",
      " 8.09788640e-270 5.09746899e-266 6.41939977e-262 1.53462954e-269]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [5.25165703e-272 5.13988929e-271 2.44956218e-270 2.52369010e-267\n",
      " 1.02447179e-262 4.41445394e-267 1.15401146e-266 6.31065742e-263\n",
      " 7.00977080e-269 2.10324408e-272 ... 2.06652694e-268 4.55133528e-272\n",
      " 2.13705416e-271 1.14727825e-269 1.59027292e-254 4.52002186e-269\n",
      " 2.31726128e-272 1.53501709e-268 2.12147115e-264 4.32483466e-272]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.45898343e-274 2.44619727e-273 1.18943630e-272 1.30866967e-269\n",
      " 5.72903552e-265 2.26036175e-269 5.87322483e-269 3.49263443e-265\n",
      " 3.58957405e-271 1.01677273e-274 ... 1.06022829e-270 2.17683726e-274\n",
      " 1.02790920e-273 5.57747367e-272 1.03536776e-256 2.27041207e-271\n",
      " 1.09004399e-274 7.56484115e-271 1.13838976e-266 2.00595170e-274]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.81940733e-276 1.83711234e-275 9.09846847e-275 1.06310803e-271\n",
      " 4.98652474e-267 1.81496777e-271 4.68961322e-271 3.01119805e-267\n",
      " 2.88289963e-273 7.74736435e-277 ... 8.52950068e-273 1.64238987e-276\n",
      " 7.79538261e-276 4.27087521e-274 1.03562998e-258 1.79145259e-273\n",
      " 8.09983771e-277 5.86512828e-273 9.54094911e-269 1.47136351e-276]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.05002767e-278 2.09834507e-277 1.05686010e-276 1.30472640e-273\n",
      " 6.51812406e-269 2.20374549e-273 5.66487151e-273 3.90191908e-269\n",
      " 3.50154690e-275 8.96808205e-279 ... 1.03757299e-274 1.88401667e-278\n",
      " 8.98417541e-278 4.96550221e-276 1.53721431e-260 2.14085585e-275\n",
      " 9.16265086e-279 6.89679411e-275 1.20473864e-270 1.64469109e-278]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [3.39908583e-280 3.52272281e-279 1.80179614e-278 2.33912157e-275\n",
      " 1.23784471e-270 3.91222220e-275 1.00090120e-274 7.35113214e-271\n",
      " 6.21856240e-277 1.52423990e-280 ... 1.84521920e-276 3.17556024e-280\n",
      " 1.52077124e-279 8.47228630e-278 3.27883879e-262 3.74591976e-277\n",
      " 1.52477061e-280 1.18897875e-276 2.21663614e-272 2.70712250e-280]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [8.03458786e-282 8.42188869e-281 4.36869324e-280 5.93831039e-277\n",
      " 3.31216215e-272 9.84267917e-277 2.50718564e-276 1.95265470e-272\n",
      " 1.56519387e-278 3.68564244e-282 ... 4.65014777e-278 7.62005944e-282\n",
      " 3.66341337e-281 2.05567439e-279 9.75523212e-264 9.30082648e-279\n",
      " 3.61627602e-282 2.91219553e-278 5.76203717e-274 6.35617136e-282]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.62924819e-283 2.78468929e-282 1.46321499e-281 2.07423034e-278\n",
      " 1.21380297e-273 3.40966902e-278 8.65058678e-278 7.10817470e-274\n",
      " 5.42460392e-280 1.23144246e-283 ... 1.61344691e-279 2.52820369e-283\n",
      " 1.21975445e-282 6.88941938e-281 3.93857666e-265 3.18352170e-280\n",
      " 1.18704779e-283 9.84417140e-280 2.05651240e-275 2.06725753e-283]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.15933610e-284 1.23953763e-283 6.59018730e-283 9.70733584e-280\n",
      " 5.93483522e-275 1.58365557e-279 4.00311264e-279 3.45432565e-275\n",
      " 2.52071759e-281 5.53430157e-285 ... 7.50501533e-281 1.12893183e-284\n",
      " 5.46415559e-284 3.10464879e-282 2.10374273e-266 1.46255475e-281\n",
      " 5.24899103e-285 4.47103773e-281 9.81531462e-277 9.06419325e-285]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [6.71816119e-286 7.24509902e-285 3.89356086e-284 5.93947907e-281\n",
      " 3.77924199e-276 9.62261475e-281 2.42417032e-280 2.18741816e-276\n",
      " 1.53238254e-282 3.26338398e-286 ... 4.56656437e-282 6.61780544e-286\n",
      " 3.21247627e-285 1.83516041e-283 1.45216749e-267 8.79890066e-283\n",
      " 3.04960253e-286 2.66172614e-282 6.11393516e-278 5.22558201e-286]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [4.99984481e-287 5.43455281e-286 2.94933989e-285 4.64509326e-282\n",
      " 3.06527798e-277 7.47789497e-282 1.87804023e-281 1.76514097e-277\n",
      " 1.19141369e-283 2.46769328e-287 ... 3.55337756e-283 4.97730833e-287\n",
      " 2.42257270e-286 1.39072139e-284 1.26774064e-268 6.77622114e-284\n",
      " 2.27500228e-287 2.03023632e-283 4.86006473e-279 3.87076351e-287]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [4.67865499e-288 5.12200377e-287 2.80470213e-286 4.54785106e-283\n",
      " 3.10243288e-278 7.27892177e-283 1.82289617e-282 1.77822688e-278\n",
      " 1.16025910e-284 2.34302968e-288 ... 3.46302769e-284 4.70260516e-288\n",
      " 2.29441955e-287 1.32302864e-285 1.37212531e-269 6.54187554e-285\n",
      " 2.13349917e-288 1.94285881e-284 4.82944085e-280 3.60655921e-288]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [5.39849686e-289 5.94877298e-288 3.28411868e-287 5.46856120e-284\n",
      " 3.84513448e-279 8.70616056e-284 2.17468251e-283 2.19456476e-279\n",
      " 1.38839459e-285 2.73971329e-289 ... 4.14672556e-285 5.47402935e-289\n",
      " 2.67669248e-288 1.54970859e-286 1.80782566e-270 7.76625252e-286\n",
      " 2.46666802e-289 2.28801034e-285 5.88613065e-281 4.14513388e-289]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [7.54438229e-290 8.36299333e-289 4.65141822e-288 7.93513313e-285\n",
      " 5.73543845e-280 1.25718718e-284 3.13285347e-284 3.26075119e-280\n",
      " 2.00574944e-286 3.87551597e-290 ... 5.99421989e-286 7.71155450e-290\n",
      " 3.77836398e-289 2.19557867e-287 2.85107784e-271 1.11385392e-286\n",
      " 3.45345946e-290 3.25749249e-286 8.64671325e-282 5.77206885e-290]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.25608235e-290 1.39993978e-289 7.83933705e-289 1.36719336e-285\n",
      " 1.01332549e-280 2.15650698e-285 5.36229670e-285 5.74067049e-281\n",
      " 3.44198784e-287 6.52434715e-291 ... 1.02920964e-286 1.29334744e-290\n",
      " 6.34846542e-290 3.70135736e-288 5.29950877e-272 1.89884825e-287\n",
      " 5.75935492e-291 5.51608369e-287 1.50656159e-282 9.57864721e-291]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [2.45406888e-291 2.74865870e-290 1.54873005e-289 2.75584967e-286\n",
      " 2.08980843e-281 4.32931942e-286 1.07438787e-285 1.18009949e-281\n",
      " 6.91274370e-288 1.28764652e-291 ... 2.06804907e-287 2.54380098e-291\n",
      " 1.25070993e-290 7.31413206e-289 1.14464374e-272 3.79065147e-288\n",
      " 1.12695135e-291 1.09444463e-287 3.06785608e-283 1.86584613e-291]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [5.54884501e-292 6.24291575e-291 3.53743402e-290 6.41089140e-287\n",
      " 4.96376847e-282 1.00341298e-286 2.48563661e-286 2.79477245e-282\n",
      " 1.60277743e-288 2.93843948e-292 ... 4.79710253e-288 5.78685096e-292\n",
      " 2.84951094e-291 1.67097364e-289 2.83567477e-273 8.74079072e-289\n",
      " 2.55168102e-292 2.50959078e-288 7.20313326e-284 4.20735307e-292]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.43363566e-292 1.61956825e-291 9.22417989e-291 1.69979592e-287\n",
      " 1.34128177e-282 2.65152886e-287 6.55751784e-287 7.53167211e-283\n",
      " 4.23684682e-289 7.65602185e-293 ... 1.26860215e-288 1.50344516e-292\n",
      " 7.41328483e-292 4.35806052e-290 7.96171064e-274 2.29903841e-289\n",
      " 6.60108480e-293 6.56725805e-289 1.92601547e-284 1.08434388e-292]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [4.18341108e-293 4.74358544e-292 2.71433518e-291 5.07834368e-288\n",
      " 4.07694362e-283 7.89749078e-288 1.95020580e-287 2.28373860e-283\n",
      " 1.26234692e-289 2.25123699e-293 ... 3.78112968e-289 4.40934651e-293\n",
      " 2.17689872e-292 1.28263886e-290 2.50591551e-274 6.81870366e-290\n",
      " 1.92846379e-293 1.93874539e-289 5.79847378e-285 3.15701266e-293]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.36407745e-293 1.55197656e-292 8.91842400e-292 1.69177954e-288\n",
      " 1.37965400e-283 2.62359300e-288 6.46984171e-288 7.71111262e-284\n",
      " 4.19488194e-290 7.39196378e-294 ... 1.25691997e-289 1.44438117e-293\n",
      " 7.13900046e-293 4.21499076e-291 8.75351556e-275 2.25652120e-290\n",
      " 6.29477385e-294 6.38878606e-290 1.94519046e-285 1.02728235e-293]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [4.92173087e-294 5.61695600e-293 3.24029146e-292 6.22438180e-289\n",
      " 5.14897168e-284 9.62814581e-289 2.37136558e-288 2.87203123e-284\n",
      " 1.53989250e-290 2.68409640e-294 ... 4.61540302e-290 5.23336321e-294\n",
      " 2.58930494e-293 1.53162768e-291 3.36255129e-275 8.25217203e-291\n",
      " 2.27341414e-294 2.32739850e-290 7.20222006e-286 3.69959000e-294]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.94751938e-294 2.22885000e-293 1.29030524e-292 2.50707994e-289\n",
      " 2.10101388e-284 3.86907488e-289 9.51853077e-289 1.16976445e-284\n",
      " 6.18971268e-291 1.06825329e-294 ... 1.85570383e-290 2.07874729e-294\n",
      " 1.02946106e-293 6.09980565e-292 1.40857151e-275 3.30562877e-291\n",
      " 9.00378149e-295 9.29029794e-291 2.91769405e-286 1.46142141e-294]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [8.38257975e-295 9.61794433e-294 5.58578566e-293 1.09666553e-289\n",
      " 9.29950526e-285 1.68886874e-289 4.15058897e-289 5.16894962e-285\n",
      " 2.70250439e-291 4.62228381e-295 ... 8.10424041e-291 8.97853355e-295\n",
      " 4.45022938e-294 2.64092863e-292 6.38524295e-276 1.43876657e-291\n",
      " 3.87854957e-295 4.03065480e-291 1.28297795e-286 6.28052516e-295]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [3.89545022e-295 4.47988832e-294 2.60935770e-293 5.17163928e-290\n",
      " 4.43274537e-285 7.94904710e-290 1.95173226e-289 2.46010681e-285\n",
      " 1.27228590e-291 2.15832592e-295 ... 3.81617426e-291 4.18559460e-295\n",
      " 2.07619967e-294 1.23381466e-292 3.11039780e-276 6.75416677e-292\n",
      " 1.80371015e-295 1.88665073e-291 6.07909775e-287 2.91448171e-295]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.94112736e-295 2.23705650e-294 1.30645066e-293 2.61167536e-290\n",
      " 2.26046745e-285 4.00724933e-290 9.83059189e-290 1.25278952e-285\n",
      " 6.41516114e-292 1.08020436e-295 ... 1.92459535e-291 2.09170902e-295\n",
      " 1.03828711e-294 6.17801286e-293 1.61774075e-276 3.39679811e-292\n",
      " 8.99398543e-296 9.46319518e-292 3.08323852e-287 1.45043608e-295]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.03075676e-295 1.19017036e-294 6.96739190e-294 1.40374478e-290\n",
      " 1.22578784e-285 2.15042474e-290 5.27131844e-290 6.78497848e-286\n",
      " 3.44326061e-292 5.75876350e-296 ... 1.03319384e-291 1.11362268e-295\n",
      " 5.53134242e-295 3.29504660e-293 8.93124787e-277 1.81890164e-292\n",
      " 4.77878482e-296 5.05509716e-292 1.66372390e-287 7.69293795e-296]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [5.79948685e-296 6.70805533e-295 3.93556914e-294 7.98560350e-291\n",
      " 7.02961015e-286 1.22156141e-290 2.99228281e-290 3.88657891e-286\n",
      " 1.95631473e-292 3.25182806e-296 ... 5.87114957e-292 6.28062714e-296\n",
      " 3.12137797e-295 1.86136200e-293 5.20598493e-277 1.03121256e-292\n",
      " 2.69023568e-296 2.85966706e-292 9.49838263e-288 4.32377612e-296]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [3.43950363e-296 3.98462911e-295 2.34240448e-294 4.78368592e-291\n",
      " 4.24191907e-286 7.30800282e-291 1.78898329e-290 2.34286380e-286\n",
      " 1.17055997e-292 1.93489050e-296 ... 3.51353077e-292 3.73290449e-296\n",
      " 1.85617105e-295 1.10793423e-293 3.18831663e-277 6.15825962e-293\n",
      " 1.59629965e-296 1.70434945e-292 5.70835760e-288 2.56182238e-296]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [2.14000324e-296 2.48272597e-295 1.46213308e-294 3.00352912e-291\n",
      " 2.68112168e-286 4.58298399e-291 1.12124781e-290 1.47941792e-286\n",
      " 7.34190985e-293 1.20744680e-296 ... 2.20403568e-292 2.32711407e-296\n",
      " 1.15769872e-295 6.91615838e-294 2.04246137e-277 3.85571892e-293\n",
      " 9.93645034e-297 1.06516802e-292 3.59465835e-288 1.59252246e-296]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [1.39080571e-296 1.61564479e-295 9.53051309e-295 1.96821305e-291\n",
      " 1.76757064e-286 2.99996629e-291 7.33564858e-291 9.74492244e-287\n",
      " 4.80659398e-293 7.86855379e-297 ... 1.44311481e-292 1.51510932e-296\n",
      " 7.54066294e-296 4.50835063e-294 1.36306447e-277 2.52020565e-293\n",
      " 6.46046140e-297 6.95076419e-293 2.36187839e-288 1.03416623e-296]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [9.40456464e-297 1.09378305e-295 6.46172545e-295 1.34092031e-291\n",
      " 1.21083972e-286 2.04182311e-291 4.99034128e-291 6.67036669e-287\n",
      " 3.27185869e-293 5.33377304e-297 ... 9.82441674e-293 1.02617062e-296\n",
      " 5.10923013e-296 3.05682781e-294 9.44150142e-278 1.71300733e-293\n",
      " 4.37018312e-297 4.71742436e-293 1.61302513e-288 6.98790632e-297]\n",
      "\n",
      "training\n",
      "train loss 0.03597500513434896\n",
      "val loss 0.04828044076052047\n",
      "true [0.04575 0.05275 0.16675 0.08275 0.1145  0.15625 0.05025 0.11175 0.0395\n",
      " 0.08    ... 0.0375  0.02825 0.012   0.03575 0.13    0.04875 0.01975\n",
      " 0.0105  0.10925 0.0185 ]\n",
      "pred [6.59279649e-297 7.67587634e-296 4.54080374e-295 9.46439398e-292\n",
      " 8.58887713e-287 1.43985273e-291 3.51754304e-291 4.72815806e-287\n",
      " 2.30751874e-293 3.74744319e-297 ... 6.92949623e-293 7.20426067e-297\n",
      " 3.58822672e-296 2.14819749e-294 6.76491366e-278 1.20651915e-293\n",
      " 3.06464072e-297 3.31809313e-293 1.14100233e-288 4.89543656e-297]\n",
      "\n",
      "\r"
     ]
    }
   ],
   "source": [
    "train_relevances = movie_tag_relevances[1000:]\n",
    "val_relevances = movie_tag_relevances[:1000]\n",
    "print(\"num training examples\", len(train_relevances))\n",
    "\n",
    "plot_weights = True\n",
    "\n",
    "learning_rate=.01\n",
    "epochs=60\n",
    "\n",
    "mse_loss_term = tf.reduce_mean(tf.squared_difference(pred_y, movie_tag_relevances_var))\n",
    "loss = mse_loss_term\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), leave=False):\n",
    "        val_loss_val = sess.run(loss, feed_dict={movie_tag_relevances_var: val_relevances})\n",
    "        print(\"training\")\n",
    "        _, val_loss = sess.run((train_step, loss), feed_dict={movie_tag_relevances_var: train_relevances})\n",
    "        print(\"train loss\", val_loss)\n",
    "#         print(\"l1 weights\", sess.run(W4, feed_dict={movie_tag_relevances_var: train_relevances}))\n",
    "\n",
    "        val_loss_val = sess.run(loss, feed_dict={movie_tag_relevances_var: val_relevances})\n",
    "\n",
    "        print(\"val loss\", val_loss_val)\n",
    "        print(\"true\", val_relevances[0])\n",
    "        print(\"pred\", sess.run(pred_y[0], feed_dict={movie_tag_relevances_var: val_relevances}))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "train_relevances = movie_tag_relevances[1000:]\n",
    "val_relevances = movie_tag_relevances[:1000]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_relevances)\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_relevances = scaler.transform(train_relevances)\n",
    "val_relevances = scaler.transform(val_relevances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6, 0.7, 0.8, 0.82, 0.83, 0.84, 0.85]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70e6c7970b44a989ce288ac20118a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[(0.6, 58, 0.39966983), (0.7, 121, 0.29934865), (0.8, 239, 0.19993259), (0.82, 273, 0.17949584), (0.83, 291, 0.16963671), (0.84, 310, 0.1598199), (0.85, 331, 0.14967214)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f4e4b004fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variances = [.6, .7, .8, .82, .83, .84, .85]\n",
    "print(variances)\n",
    "dimensions = []\n",
    "val_mses = []\n",
    "\n",
    "for variance in tqdm(variances):\n",
    "    model = PCA(variance).fit(train_relevances)\n",
    "\n",
    "    reduced_train_relevances = model.transform(train_relevances)\n",
    "    pred_train_relevances = model.inverse_transform(reduced_train_relevances)\n",
    "\n",
    "    reduced_val_relevances = model.transform(val_relevances)\n",
    "    pred_val_relevances = model.inverse_transform(reduced_val_relevances)\n",
    "    dimensions.append(reduced_val_relevances.shape[1])\n",
    "\n",
    "    val_mse = np.mean((pred_train_relevances - train_relevances)*(pred_train_relevances - train_relevances))\n",
    "    val_mses.append(val_mse)\n",
    "#     print(np.mean((pred_val_relevances - val_relevances)*(pred_val_relevances - val_relevances)))\n",
    "\n",
    "print(list(zip(variances, dimensions, val_mses)))\n",
    "\n",
    "plt.scatter(dimensions, val_mses)\n",
    "\n",
    "# use 0.96875 as variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving dataset from dataset/train_ratings_binary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/11946576 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 183789/11946576 [00:00<00:06, 1837882.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 361784/11946576 [00:00<00:06, 1820110.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 555618/11946576 [00:00<00:06, 1854035.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 768791/11946576 [00:00<00:05, 1929436.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 991834/11946576 [00:00<00:05, 2010843.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 1216466/11946576 [00:00<00:05, 2076133.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 1448569/11946576 [00:00<00:04, 2143998.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 1682314/11946576 [00:00<00:04, 2198585.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 1915328/11946576 [00:00<00:04, 2236462.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 2152182/11946576 [00:01<00:04, 2274510.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 2390663/11946576 [00:01<00:04, 2306511.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 2628199/11946576 [00:01<00:04, 2326742.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 2870993/11946576 [00:01<00:03, 2356201.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 3115226/11946576 [00:01<00:03, 2381394.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 3352548/11946576 [00:02<00:11, 767753.30it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|██▉       | 3527598/11946576 [00:02<00:09, 910384.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 3698342/11946576 [00:02<00:08, 1030507.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 3862530/11946576 [00:02<00:07, 1133544.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▎      | 4021816/11946576 [00:02<00:08, 943877.82it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▍      | 4165985/11946576 [00:02<00:07, 1052704.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 4311712/11946576 [00:02<00:06, 1148344.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 4488569/11946576 [00:03<00:05, 1283364.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 4708398/11946576 [00:03<00:04, 1466465.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████▏     | 4931696/11946576 [00:03<00:04, 1634820.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 5153205/11946576 [00:03<00:03, 1774255.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 5385322/11946576 [00:03<00:03, 1909207.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 5615616/11946576 [00:03<00:03, 2012423.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 5853309/11946576 [00:03<00:02, 2109470.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████     | 6093792/11946576 [00:03<00:02, 2190166.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████▎    | 6324352/11946576 [00:03<00:02, 2223561.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 6552510/11946576 [00:03<00:02, 2236149.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 6786205/11946576 [00:04<00:02, 2265463.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 7021010/11946576 [00:04<00:02, 2289622.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████    | 7257227/11946576 [00:04<00:02, 2310913.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████▎   | 7496421/11946576 [00:04<00:01, 2334637.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 7731471/11946576 [00:04<00:01, 2339371.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 7972498/11946576 [00:04<00:01, 2360198.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▊   | 8210020/11946576 [00:04<00:01, 2364683.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████   | 8448911/11946576 [00:04<00:01, 2371895.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████▎  | 8687975/11946576 [00:04<00:01, 2377485.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▍  | 8925938/11946576 [00:04<00:01, 2375922.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 9163681/11946576 [00:05<00:01, 2366338.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████▊  | 9402688/11946576 [00:05<00:01, 2373406.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 9642407/11946576 [00:05<00:00, 2380489.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 9880521/11946576 [00:05<00:00, 2372612.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 10119316/11946576 [00:05<00:00, 2377190.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████▋ | 10357073/11946576 [00:05<00:00, 2368383.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████▊ | 10598289/11946576 [00:05<00:00, 2381347.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████ | 10836465/11946576 [00:05<00:00, 2376219.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|█████████▎| 11074118/11946576 [00:05<00:00, 2374322.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▍| 11312045/11946576 [00:05<00:00, 2375802.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████▋| 11549641/11946576 [00:06<00:00, 2371056.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 11946576/11946576 [00:06<00:00, 1913931.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projected down to 646 dims from 1128 dimensions (reduced by 0.4273049645390071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use pca to reduce dimensions with preserved_variance=0.96875 => dim=768 (reduction by 32%), val mse=0.031122472 on scaled data\n",
    "preserved_variance = 0.90\n",
    "\n",
    "user_Xs, movie_Xs, ys = get_dataset(train_set, include_ys=True, recompute=False)\n",
    "train_tags = get_tags(movie_Xs, preserved_variance, recompute=False)\n",
    "\n",
    "NUM_PROJ_TAGS = train_tags[0].shape[0]\n",
    "print(f\"projected down to {NUM_PROJ_TAGS} dims from {NUM_TAGS} dimensions (reduced by {1-NUM_PROJ_TAGS/NUM_TAGS})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.19499993, 0.26932433, 0.16548704, 0.30513933, 0.25957322,\n",
      "       0.31468445, 0.21783373, 0.33380088, 0.32604718, 0.35116148,\n",
      "       0.24623372, 0.2825228 , 0.27335486, 0.3139616 , 0.3031217 ,\n",
      "       0.24353845, 0.22127065, 0.2964685 , 0.2799396 , 0.2585362 ,\n",
      "       0.29813728, 0.25344273, 0.31887996, 0.32067055, 0.27661493,\n",
      "       0.31390274, 0.2841844 , 0.34395897, 0.30886206, 0.3419188 ,\n",
      "       0.28596923, 0.3058844 , 0.3279011 , 0.2711107 , 0.27848014,\n",
      "       0.26054803, 0.29566747, 0.2884222 , 0.32165137, 0.29650766,\n",
      "       0.30496567, 0.2861339 , 0.28910568, 0.27990335, 0.28922498,\n",
      "       0.27595046, 0.29772282, 0.28098527, 0.29738665, 0.29211843,\n",
      "       0.29760945, 0.26875883, 0.2808908 , 0.3021804 , 0.30604818,\n",
      "       0.283767  , 0.31507048, 0.2733025 , 0.30144453, 0.26626727,\n",
      "       0.2735752 , 0.2790814 , 0.26703948, 0.29587737, 0.3031414 ,\n",
      "       0.30196437, 0.30051717, 0.301843  , 0.29942873, 0.30721503,\n",
      "       0.27768773, 0.29579383, 0.29635638, 0.31578767, 0.28268117,\n",
      "       0.29230595, 0.3045641 , 0.2915858 , 0.28015387, 0.28881624,\n",
      "       0.3165227 , 0.2937346 , 0.29861948, 0.2769115 , 0.29168975,\n",
      "       0.31660596, 0.28812027, 0.28665096, 0.3040605 , 0.2967414 ,\n",
      "       0.3048282 , 0.28985748, 0.29476392, 0.29131114, 0.29869506,\n",
      "       0.26766834, 0.27526245, 0.28157458, 0.3013161 , 0.2885054 ,\n",
      "       0.27704418, 0.28778848, 0.30612087, 0.2912461 , 0.27704746,\n",
      "       0.29466426, 0.3032071 , 0.28647766, 0.28560692, 0.30202675,\n",
      "       0.30176523, 0.29117057, 0.29452127, 0.27648547, 0.2936    ,\n",
      "       0.28981766, 0.28916296, 0.3081983 , 0.2931933 , 0.28135738,\n",
      "       0.29265675, 0.30158764, 0.30675015, 0.28524268, 0.28866553,\n",
      "       0.307797  , 0.29273698, 0.308953  , 0.2975012 , 0.28114933,\n",
      "       0.30007228, 0.29910973, 0.30338454, 0.30333176, 0.2881195 ,\n",
      "       0.29899523, 0.29754725, 0.29572046, 0.30131948, 0.2876777 ,\n",
      "       0.2891144 , 0.27789122, 0.29775313, 0.2905415 , 0.3015976 ,\n",
      "       0.29390332, 0.29473364, 0.30402026, 0.2843926 , 0.30549958,\n",
      "       0.28757912, 0.29802093, 0.29369155, 0.3021706 , 0.30581835,\n",
      "       0.29487932, 0.3032123 , 0.3053155 , 0.293842  , 0.3050755 ,\n",
      "       0.30312243, 0.2968675 , 0.29646778, 0.30937716, 0.3052199 ,\n",
      "       0.28030264, 0.28407863, 0.2919984 , 0.28776824, 0.29277515,\n",
      "       0.28926298, 0.30159557, 0.2997746 , 0.29759097, 0.29248425,\n",
      "       0.2871849 , 0.29062605, 0.2897742 , 0.29718783, 0.28580695,\n",
      "       0.28966343, 0.29599035, 0.3063933 , 0.29627025, 0.29471117,\n",
      "       0.30244896, 0.294708  , 0.29890916, 0.27496442, 0.30640346,\n",
      "       0.28657958, 0.3009706 , 0.31333494, 0.29657176, 0.29813895,\n",
      "       0.29653716, 0.29096738, 0.31226936, 0.29209834, 0.30324894,\n",
      "       0.28496206, 0.28455845, 0.29975575, 0.3039295 , 0.30481696,\n",
      "       0.2855055 , 0.2878207 , 0.30705112, 0.29488686, 0.29297248,\n",
      "       0.3027504 , 0.28580987, 0.301725  , 0.2875349 , 0.29751372,\n",
      "       0.28652757, 0.29607493, 0.30628213, 0.29655215, 0.29576012,\n",
      "       0.29011378, 0.29713613, 0.28789523, 0.3134303 , 0.3038155 ,\n",
      "       0.29471695, 0.3076385 , 0.29749295], dtype=float32), array([0.747714  , 0.6107897 , 0.4273798 , 0.18142946, 0.2430733 ,\n",
      "       0.38249415, 0.04672519, 0.31439528, 0.26960385, 0.32182872,\n",
      "       0.2685221 , 0.29788473, 0.25431606, 0.22633524, 0.36414522,\n",
      "       0.3584527 , 0.298495  , 0.41502663, 0.284838  , 0.25933737,\n",
      "       0.2868145 , 0.32228452, 0.25432324, 0.31020898, 0.3450789 ,\n",
      "       0.3455149 , 0.24386235, 0.27048123, 0.2552537 , 0.2899475 ,\n",
      "       0.27137998, 0.32318893, 0.24973775, 0.29651996, 0.26591176,\n",
      "       0.30832526, 0.2803545 , 0.26608017, 0.30746198, 0.35524866,\n",
      "       0.32519892, 0.32500184, 0.3183934 , 0.30411342, 0.33015668,\n",
      "       0.30577844, 0.29061922, 0.32758805, 0.28867286, 0.2736864 ,\n",
      "       0.28430158, 0.3250431 , 0.33434564, 0.27610633, 0.30881253,\n",
      "       0.34113926, 0.25614527, 0.33286572, 0.26979488, 0.29118943,\n",
      "       0.3026351 , 0.30961093, 0.30465922, 0.2868694 , 0.31064638,\n",
      "       0.2981833 , 0.26000056, 0.2795483 , 0.27708656, 0.3187979 ,\n",
      "       0.29020685, 0.28851512, 0.28295568, 0.29368427, 0.30092385,\n",
      "       0.31048417, 0.32771328, 0.27454022, 0.31650597, 0.29496545,\n",
      "       0.29148203, 0.30215064, 0.2826446 , 0.30912292, 0.28494972,\n",
      "       0.28355384, 0.31674743, 0.3068861 , 0.28747094, 0.30110714,\n",
      "       0.30999875, 0.29079694, 0.2897244 , 0.28422895, 0.3033512 ,\n",
      "       0.2912731 , 0.29773933, 0.32984224, 0.33553943, 0.3240739 ,\n",
      "       0.30735183, 0.3002684 , 0.27174532, 0.31175324, 0.3003853 ,\n",
      "       0.3171669 , 0.31921327, 0.2891013 , 0.2942038 , 0.3024807 ,\n",
      "       0.28116387, 0.31181508, 0.30919078, 0.29040834, 0.28859147,\n",
      "       0.29096693, 0.3184238 , 0.3089565 , 0.28892073, 0.30193728,\n",
      "       0.3062133 , 0.29126292, 0.30468547, 0.28291416, 0.31836018,\n",
      "       0.31376162, 0.3082982 , 0.32996136, 0.30992678, 0.28726137,\n",
      "       0.31116596, 0.31016096, 0.3267937 , 0.31189746, 0.29151452,\n",
      "       0.30182654, 0.30813935, 0.29537368, 0.27188066, 0.3016601 ,\n",
      "       0.28605884, 0.28765166, 0.30919096, 0.2906226 , 0.29507294,\n",
      "       0.28428176, 0.31787413, 0.29904434, 0.28920966, 0.27320525,\n",
      "       0.29392853, 0.29050857, 0.30779687, 0.31305438, 0.29670078,\n",
      "       0.30868772, 0.28345823, 0.27971634, 0.2957357 , 0.31560984,\n",
      "       0.30764422, 0.29457787, 0.3023156 , 0.31341788, 0.29033124,\n",
      "       0.31338218, 0.30042568, 0.31090987, 0.27673757, 0.27258876,\n",
      "       0.28700152, 0.2913116 , 0.3229665 , 0.31274238, 0.30421954,\n",
      "       0.2917763 , 0.2847806 , 0.30421293, 0.26962194, 0.28882703,\n",
      "       0.3139447 , 0.28395814, 0.28620312, 0.30818632, 0.31245148,\n",
      "       0.3001526 , 0.2782093 , 0.2889159 , 0.30323812, 0.28627196,\n",
      "       0.2796047 , 0.2993766 , 0.29568377, 0.27523327, 0.28393248,\n",
      "       0.31533903, 0.30676708, 0.286728  , 0.28081563, 0.30849716,\n",
      "       0.29596958, 0.30407336, 0.29388377, 0.30537152, 0.28425607,\n",
      "       0.29446885, 0.2940782 , 0.29138315, 0.30537826, 0.28527716,\n",
      "       0.27406436, 0.28611088, 0.2948836 , 0.30267605, 0.30239114,\n",
      "       0.29230365, 0.27395073, 0.31547815, 0.2839503 , 0.2864344 ,\n",
      "       0.29968607, 0.30026406, 0.30063638, 0.2918424 , 0.30771372,\n",
      "       0.28954253, 0.27755365, 0.2900103 ], dtype=float32), array([0.33273974, 0.34954056, 0.20490722, 0.2689266 , 0.23607449,\n",
      "       0.21726294, 0.33476907, 0.30135873, 0.3474111 , 0.31990957,\n",
      "       0.24788716, 0.2522434 , 0.28461942, 0.20629662, 0.3152708 ,\n",
      "       0.2913472 , 0.26308715, 0.23908775, 0.23016511, 0.257247  ,\n",
      "       0.31106535, 0.2501399 , 0.2495169 , 0.29716069, 0.31419295,\n",
      "       0.2718105 , 0.31935376, 0.2789508 , 0.2593019 , 0.29733112,\n",
      "       0.3188342 , 0.3385387 , 0.37837353, 0.24676748, 0.34306204,\n",
      "       0.25921726, 0.30369875, 0.30209982, 0.28079167, 0.24070647,\n",
      "       0.33578476, 0.2969567 , 0.33759913, 0.27518448, 0.24496455,\n",
      "       0.32165086, 0.2935173 , 0.32739675, 0.29345626, 0.27930823,\n",
      "       0.32902184, 0.2765186 , 0.29310003, 0.2894181 , 0.28100604,\n",
      "       0.29739136, 0.2890687 , 0.3080444 , 0.2973629 , 0.28769478,\n",
      "       0.32083884, 0.26703477, 0.30133474, 0.27789566, 0.29923812,\n",
      "       0.30877876, 0.2528425 , 0.27633783, 0.2909151 , 0.28121462,\n",
      "       0.30250835, 0.30925873, 0.27182275, 0.3055924 , 0.30826974,\n",
      "       0.28076288, 0.28254393, 0.3175318 , 0.23512846, 0.2921074 ,\n",
      "       0.2813393 , 0.30529374, 0.29506728, 0.29148662, 0.2742486 ,\n",
      "       0.30306154, 0.3112748 , 0.30678532, 0.28235435, 0.2984649 ,\n",
      "       0.29499653, 0.329708  , 0.29582456, 0.2516589 , 0.29336077,\n",
      "       0.30569997, 0.30260748, 0.3004123 , 0.29192945, 0.30114824,\n",
      "       0.2730143 , 0.28729883, 0.29344702, 0.28819677, 0.30132097,\n",
      "       0.28965643, 0.27591968, 0.29336807, 0.31152958, 0.2873742 ,\n",
      "       0.31684446, 0.3232297 , 0.26898357, 0.2678943 , 0.28294736,\n",
      "       0.3008234 , 0.30045584, 0.27929077, 0.30122516, 0.30176422,\n",
      "       0.28775477, 0.27383828, 0.29588145, 0.29312217, 0.28744936,\n",
      "       0.29003382, 0.29372898, 0.29605073, 0.29515293, 0.2996476 ,\n",
      "       0.3127897 , 0.2973566 , 0.28618383, 0.2634388 , 0.31351054,\n",
      "       0.28163695, 0.32255575, 0.28179225, 0.30614287, 0.3050634 ,\n",
      "       0.29650137, 0.30422693, 0.28431338, 0.27642515, 0.3151167 ,\n",
      "       0.28397486, 0.2950256 , 0.29838455, 0.28805038, 0.30134562,\n",
      "       0.3126894 , 0.30454895, 0.3059024 , 0.2980634 , 0.29589754,\n",
      "       0.2992736 , 0.2677505 , 0.29988506, 0.30615398, 0.31142202,\n",
      "       0.31671175, 0.2958086 , 0.2998896 , 0.30327788, 0.28665513,\n",
      "       0.28281072, 0.30386385, 0.26997527, 0.28971046, 0.28995308,\n",
      "       0.2964648 , 0.30023873, 0.2922776 , 0.29879257, 0.28628162,\n",
      "       0.30006292, 0.29143426, 0.2872752 , 0.27729103, 0.3003127 ,\n",
      "       0.3091476 , 0.30362564, 0.29685682, 0.30723324, 0.29371774,\n",
      "       0.3081232 , 0.29394045, 0.31803617, 0.30980423, 0.28425083,\n",
      "       0.3136844 , 0.29297376, 0.28727308, 0.2996851 , 0.26745597,\n",
      "       0.26397997, 0.3082073 , 0.29802865, 0.2772823 , 0.26065564,\n",
      "       0.29928535, 0.32229477, 0.29809067, 0.3017929 , 0.26665685,\n",
      "       0.305153  , 0.2734097 , 0.2815869 , 0.29880732, 0.29419634,\n",
      "       0.2845065 , 0.30510828, 0.29540655, 0.2520699 , 0.29937068,\n",
      "       0.29814807, 0.30029175, 0.27249852, 0.30667382, 0.29669943,\n",
      "       0.28003696, 0.29155123, 0.30477837, 0.26537964, 0.32423946,\n",
      "       0.31830344, 0.31170657, 0.28171378], dtype=float32), array([0.10197995, 0.3692933 , 0.30373043, 0.31283578, 0.25323775,\n",
      "       0.30295494, 0.32915363, 0.2989475 , 0.29001498, 0.30654737,\n",
      "       0.29042625, 0.2680989 , 0.29054356, 0.2918642 , 0.30309525,\n",
      "       0.36831212, 0.24471621, 0.23262249, 0.37539753, 0.2935332 ,\n",
      "       0.30236742, 0.2905644 , 0.33881572, 0.2516427 , 0.29723355,\n",
      "       0.3046972 , 0.31757337, 0.2529351 , 0.29231834, 0.2602817 ,\n",
      "       0.26338956, 0.29146844, 0.292568  , 0.2816855 , 0.24274546,\n",
      "       0.294415  , 0.27263725, 0.27205357, 0.2864119 , 0.2975437 ,\n",
      "       0.3180228 , 0.28492624, 0.35519385, 0.33949783, 0.31406003,\n",
      "       0.31390566, 0.28983206, 0.30074728, 0.28423962, 0.29862   ,\n",
      "       0.29539073, 0.3029428 , 0.296138  , 0.30968174, 0.2581532 ,\n",
      "       0.30455506, 0.30955923, 0.28094944, 0.29261836, 0.30025983,\n",
      "       0.28481725, 0.31519344, 0.27786404, 0.33714816, 0.2758318 ,\n",
      "       0.26238272, 0.297091  , 0.2986768 , 0.30089778, 0.28928283,\n",
      "       0.30426398, 0.28176662, 0.32155505, 0.30417848, 0.2759263 ,\n",
      "       0.2569382 , 0.29912993, 0.27018455, 0.31716415, 0.30143934,\n",
      "       0.28421396, 0.27064052, 0.3004152 , 0.29728004, 0.30549774,\n",
      "       0.30214947, 0.25902957, 0.2933002 , 0.32122725, 0.27560472,\n",
      "       0.3099884 , 0.3102998 , 0.2913078 , 0.31265765, 0.3068991 ,\n",
      "       0.2958053 , 0.3013194 , 0.29832438, 0.30258286, 0.2714892 ,\n",
      "       0.29897   , 0.28368083, 0.29178828, 0.2630591 , 0.29771036,\n",
      "       0.30203032, 0.27979916, 0.30080158, 0.30070946, 0.2758307 ,\n",
      "       0.28076228, 0.27263507, 0.29305464, 0.30043125, 0.30900595,\n",
      "       0.27608833, 0.2964128 , 0.2791106 , 0.30496716, 0.31237137,\n",
      "       0.28714588, 0.30437413, 0.3105927 , 0.31520078, 0.29739818,\n",
      "       0.3036076 , 0.3045675 , 0.30109298, 0.2786069 , 0.2988188 ,\n",
      "       0.29255238, 0.29595718, 0.29144084, 0.2917887 , 0.31830662,\n",
      "       0.2889973 , 0.2836232 , 0.27496964, 0.2918968 , 0.29993403,\n",
      "       0.30104244, 0.2953155 , 0.3134046 , 0.3004017 , 0.29629034,\n",
      "       0.2832289 , 0.2914228 , 0.28008613, 0.31295088, 0.298432  ,\n",
      "       0.294661  , 0.3127301 , 0.29531148, 0.30170584, 0.29772252,\n",
      "       0.29512793, 0.3003352 , 0.30351222, 0.28273138, 0.30196422,\n",
      "       0.28797832, 0.27151245, 0.2771829 , 0.30446786, 0.32154423,\n",
      "       0.3229936 , 0.30514845, 0.30512172, 0.29478088, 0.28578976,\n",
      "       0.27678394, 0.29031724, 0.29070565, 0.3026994 , 0.30178958,\n",
      "       0.29902425, 0.28451815, 0.2914241 , 0.30031204, 0.29023123,\n",
      "       0.29734144, 0.30257377, 0.27062947, 0.2999806 , 0.29496792,\n",
      "       0.30422688, 0.28281283, 0.3019839 , 0.29644194, 0.28887162,\n",
      "       0.29911545, 0.29484013, 0.28516364, 0.28872246, 0.28243154,\n",
      "       0.3137172 , 0.2941598 , 0.30320156, 0.29016706, 0.29723686,\n",
      "       0.2848188 , 0.29332504, 0.30790395, 0.29259127, 0.2914811 ,\n",
      "       0.29677853, 0.30184546, 0.26959267, 0.30736226, 0.3098475 ,\n",
      "       0.30645826, 0.27813753, 0.28484017, 0.2882055 , 0.2906877 ,\n",
      "       0.28279293, 0.2787827 , 0.29733813, 0.30281138, 0.29177332,\n",
      "       0.3046904 , 0.3138467 , 0.292809  , 0.29415438, 0.29599422,\n",
      "       0.2973076 , 0.299353  , 0.29106462], dtype=float32), array([0.10311753, 0.5403377 , 0.3942281 , 0.33125716, 0.31305745,\n",
      "       0.29454395, 0.37562516, 0.1798041 , 0.39794838, 0.2551438 ,\n",
      "       0.30126125, 0.1916824 , 0.32118225, 0.43995973, 0.2432999 ,\n",
      "       0.2780898 , 0.33750874, 0.3470677 , 0.23114923, 0.2830385 ,\n",
      "       0.33112392, 0.3167701 , 0.46079552, 0.24340664, 0.23869309,\n",
      "       0.29558113, 0.2820518 , 0.24523336, 0.32174572, 0.3196583 ,\n",
      "       0.28997958, 0.2559569 , 0.289617  , 0.23851824, 0.33588925,\n",
      "       0.33986512, 0.25669932, 0.29311487, 0.28214517, 0.2485119 ,\n",
      "       0.32404202, 0.31979075, 0.32944852, 0.3113588 , 0.26560527,\n",
      "       0.26916838, 0.2968341 , 0.3046332 , 0.3006559 , 0.27252582,\n",
      "       0.2930807 , 0.30371726, 0.30789682, 0.2951532 , 0.2872452 ,\n",
      "       0.32378906, 0.26864025, 0.2690531 , 0.2942559 , 0.3055647 ,\n",
      "       0.29514503, 0.2976246 , 0.3070069 , 0.30339766, 0.32699648,\n",
      "       0.2835739 , 0.31269196, 0.28801683, 0.2802404 , 0.31408647,\n",
      "       0.28406557, 0.30423436, 0.2860484 , 0.30261093, 0.29616874,\n",
      "       0.30614528, 0.26347616, 0.26510307, 0.31292805, 0.27209932,\n",
      "       0.29781517, 0.2978222 , 0.27856618, 0.31078622, 0.28568903,\n",
      "       0.2798643 , 0.2886311 , 0.31274956, 0.2943917 , 0.2862735 ,\n",
      "       0.28568017, 0.32117692, 0.31316155, 0.30441567, 0.29276925,\n",
      "       0.2895358 , 0.28201312, 0.31000865, 0.3026096 , 0.25790405,\n",
      "       0.2805712 , 0.322134  , 0.29377177, 0.2736791 , 0.2825008 ,\n",
      "       0.3018442 , 0.32387257, 0.28570735, 0.30042353, 0.26838997,\n",
      "       0.2935693 , 0.29686725, 0.3110867 , 0.2584559 , 0.26178655,\n",
      "       0.27788806, 0.2615285 , 0.31266347, 0.29965702, 0.2909037 ,\n",
      "       0.3152519 , 0.29797435, 0.31731564, 0.31572688, 0.30828643,\n",
      "       0.30470464, 0.3339696 , 0.2803368 , 0.2774213 , 0.29615915,\n",
      "       0.2824525 , 0.2801826 , 0.27865052, 0.28247455, 0.30113217,\n",
      "       0.29367778, 0.29442546, 0.29848862, 0.28918546, 0.30737796,\n",
      "       0.29351455, 0.27131334, 0.27389404, 0.29746756, 0.30801705,\n",
      "       0.31516516, 0.2799572 , 0.30095318, 0.3281702 , 0.28756684,\n",
      "       0.29358363, 0.26509652, 0.29868448, 0.2851802 , 0.3119067 ,\n",
      "       0.29005134, 0.30281287, 0.2771616 , 0.29196033, 0.30662408,\n",
      "       0.30172372, 0.30212155, 0.2837864 , 0.30164823, 0.30036315,\n",
      "       0.26918623, 0.28238565, 0.31239617, 0.29307443, 0.28823256,\n",
      "       0.28832474, 0.3115168 , 0.28363395, 0.30616793, 0.30753747,\n",
      "       0.2985143 , 0.29448995, 0.2801217 , 0.29746568, 0.28674397,\n",
      "       0.30417955, 0.29291332, 0.30545568, 0.30167073, 0.2872782 ,\n",
      "       0.30145425, 0.29331452, 0.2939477 , 0.30213925, 0.3112743 ,\n",
      "       0.2948901 , 0.28630733, 0.2994209 , 0.28125614, 0.28366405,\n",
      "       0.30542463, 0.28116354, 0.29745543, 0.28487122, 0.30656952,\n",
      "       0.28880808, 0.29851726, 0.3114307 , 0.30006328, 0.3106823 ,\n",
      "       0.31879854, 0.28646073, 0.30918348, 0.27776328, 0.324704  ,\n",
      "       0.29471016, 0.28551534, 0.29048577, 0.29999578, 0.3202138 ,\n",
      "       0.28858015, 0.29263225, 0.3117483 , 0.28781694, 0.30304363,\n",
      "       0.28708714, 0.3139845 , 0.27501953, 0.29449216, 0.29808316,\n",
      "       0.28473505, 0.28512922, 0.28083587], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(train_tags[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"counting movie percentage that straight up have no tags/movies with at least 1 tag with 0 relevance/total movies\")\n",
    "\n",
    "at_least_a_0 = []\n",
    "all_0s = []\n",
    "for i, row in enumerate(tqdm(movie_tag_relevances)):\n",
    "    if 0 in row:\n",
    "        at_least_a_0.append(i)\n",
    "        if sum([1 for e in row if e == 0]) == NUM_TAGS:\n",
    "            all_0s.append(i)\n",
    "print(\"total movies\", i+1)\n",
    "print(\"movies with at least 1 irrelevant tag\", len(at_least_a_0))\n",
    "print(\"movies with no tags\", len(all_0s))\n",
    "\n",
    "# CONCLUSION: IF A MOVIE HAS AT LEAST ONE TAG WITH 0 RELEVANCE, THAT MOVIE HAS NO TAG INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies_with_missing_tags = set(get_movies_with_missing_tags())\n",
    "movieid_mid_lookup = get_movieid_mid_lookup()\n",
    "\n",
    "def count_na(filename):\n",
    "    print(\"counting movie records (will have more movie records than straight up movies) that don't have any tags\")\n",
    "    na_ct, valid_ct = 0, 0\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for rating in tqdm(reader):\n",
    "            movieid = int(float(rating[\"movieId\"]))\n",
    "            if movieid_mid_lookup[movieid] in movies_with_missing_tags:\n",
    "                na_ct += 1\n",
    "            else:\n",
    "                valid_ct += 1\n",
    "    return na_ct, valid_ct\n",
    "\n",
    "na_ct, valid_ct = count_na(movie_review_relevance)\n",
    "print(na_ct/(na_ct+valid_ct), \" movie_review_relevance entries have no tag info\")\n",
    "na_ct, valid_ct = count_na(movie_genres)\n",
    "print(na_ct/(na_ct+valid_ct), \" movie_genres entries have no tag info\")\n",
    "na_ct, valid_ct = count_na(train_set)\n",
    "print(na_ct/(na_ct+valid_ct), \" train_set entries have no tag info\")\n",
    "na_ct, valid_ct = count_na(val_set)\n",
    "print(na_ct/(na_ct+valid_ct), \" val_set entries have no tag info\")\n",
    "na_ct, valid_ct = count_na(test_set)\n",
    "print(na_ct/(na_ct+valid_ct), \" test_set entries have no tag info\")\n",
    "\n",
    "# CONCLUSION: 61.9% OF ALL MOVIES DON'T HAVE ANY TAG INFO BUT MOST MOVIES THAT ARE FREQUENTLY WATCHED HAVE FULL TAG INFO - ONLY ~3% OF TEST SET MOVIE WATCH ENTRIES HAVE NO TAG INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e4abe1044a405d8b4058291cddcb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# just verifying the earlier tag analysis\n",
    "\n",
    "movies_with_missing_tags = get_movies_with_missing_tags()\n",
    "movieid_mid_lookup = get_movieid_mid_lookup()\n",
    "movie_tags = np.zeros((NUM_MOVIES, NUM_TAGS), dtype=np.float32)\n",
    "\n",
    "with open(movie_review_relevance, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for rating in tqdm(reader):\n",
    "        movieid = int(float(rating[\"movieId\"]))\n",
    "        tagid = int(float(rating[\"tagId\"]))\n",
    "        relevance = float(rating[\"relevance\"])\n",
    "\n",
    "        mid = movieid_mid_lookup[movieid]\n",
    "        tid = tagid_to_tid(tagid)\n",
    "        movie_tags[mid, tid] = relevance\n",
    "        if mid in movies_with_missing_tags:\n",
    "            print(mid, tid, relevance)\n",
    "            \n",
    "# conclusion: yeah no tags in movies_with_missing_tags have any tag information - they're not just a bunch of literal 0s in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('figure', figsize=(20, 10))\n",
    "plt.hist(movie_tag_relevances.flatten(), bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(movie_tag_relevances.flatten(), bins=200, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33414 tags more relevant than .95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "very_relevant = [i for i in movie_tag_relevances.flatten() if i > .93]\n",
    "print(len(very_relevant), \"tags more relevant than .95\")\n",
    "plt.hist(very_relevant, bins=400, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f95346a7840>, {3: 1205, 17: 3, 2: 1830, 9: 108, 18: 7, 10: 63, 16: 12, 11: 54, 13: 15, 5: 568, 15: 8, 4: 861, 25: 1, 6: 361, 7: 238, 8: 147, 0: 2588, 1: 2261, 22: 2, 19: 3, 14: 12, 12: 29, 23: 2, 21: 2, 20: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "cutoff = .95\n",
    "counts = defaultdict(lambda: 0)\n",
    "\n",
    "for row in movie_tag_relevances:\n",
    "    count = len([i for i in row if i > cutoff])\n",
    "    counts[count] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([sum(i) for i in movie_tag_relevances], bins=200, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies_with_missing_tags = set(get_movies_with_missing_tags())\n",
    "\n",
    "liked = 0\n",
    "disliked = 0\n",
    "\n",
    "with open(train_set, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for rating in tqdm(reader):\n",
    "        movieid = int(float(rating[\"movieId\"]))\n",
    "        \n",
    "        if movieid_mid_lookup[movieid] in movies_with_missing_tags:\n",
    "            if rating[\"rating\"] == \"1\":\n",
    "                liked += 1\n",
    "            else:\n",
    "                disliked += 1\n",
    "\n",
    "print(liked, disliked)\n",
    "\n",
    "# 31.2962495% of movies with no tag information will be disliked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encountered_users = []\n",
    "\n",
    "with open(train_set, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for rating in tqdm(reader):\n",
    "        userid = int(float(rating[\"userId\"]))\n",
    "        encountered_users.append(userid)\n",
    "\n",
    "with open(val_set, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for rating in tqdm(reader):\n",
    "        userid = int(float(rating[\"userId\"]))\n",
    "        encountered_users.append(userid)\n",
    "\n",
    "encountered_users = set(encountered_users)\n",
    "\n",
    "with open(test_set, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for rating in tqdm(reader):\n",
    "        userid = int(float(rating[\"userId\"]))\n",
    "        if userid not in encountered_users:\n",
    "            print(f\"USERID {userid} NOT ENCOUNTERED IN TRAIN SET BUT IN TEST SET\")\n",
    "            \n",
    "# all users will have been seen before by training or validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movieid_mid_lookup = get_movieid_mid_lookup()\n",
    "with open(test_set, newline=\"\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for rating in tqdm(reader):\n",
    "        movieid = int(float(rating[\"movieId\"]))\n",
    "        if movieid not in movieid_mid_lookup:\n",
    "            print(f\"MOVIEID {movieid} NOT ENCOUNTERED IN TRAIN SET BUT IN TEST SET\")\n",
    "\n",
    "# all movies will have been seen before by training or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
